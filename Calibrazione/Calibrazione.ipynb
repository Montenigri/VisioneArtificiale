{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il metodo scelto per l'assignment 1 è stato il metodo di Zhang [(Link alla pagina wikipedia)](https://en.wikipedia.org/wiki/Camera_resectioning#:~:text=Zhang%27s%20method%5Bedit%5D) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'assigment 1 chiede l'implementazione di un metodo di calibrazione di una videocamera attraverso l'uso del metodo DLT o di Zhang.\n",
    "Il metodo proposto è quello di Zhang\n",
    "\n",
    "I punti da risolvere sono:\n",
    "\n",
    "- Trovare matrice K dei paramentri intrinseci\n",
    "  \n",
    "- Trovare matrice di rotazione e traslazione\n",
    "  \n",
    "- Stampare i punti sul pavimento\n",
    "  \n",
    "\n",
    "Per implementare il metodo ho utilizzato il paper scritto da Wilhelm Burger che presenta sia una spiegazione che un implementazione di base del metodo.\n",
    "\n",
    "Il metodo di Zhang prevede l'uso di scacchiere di dimensioni note per calcolare i parametri intrinseci della camera, nel caso di questa implementazione è possibile avere i valori calcolati dal metodo implementato, dal metodo integrato in open cv (camera calibrate) e l'errore attraverso la funzione calibra(*dimDataset*).\n",
    "La dimensione del dataset richiesta è di 4, 8 e 16 immagini.\n",
    "\n",
    "Il dataset presenta immagini di diversa qualità e sono poco consistenti, motivo per cui non troviamo l'aumento di precisione che ci si aspetta aumentando il numero di immagini per il metodo di zhang, notiamo inoltre, che con lo stesso dataset il metodo calibrate camera presenta un plateau dopo 4 immagini\n",
    "\n",
    "Di seguito verrà descritto il comportamento delle funzioni, i parametri di ingresso ed i risultati.\n",
    "Purtroppo non sono riuscito a completare il punto 3, in quanto non sono stato in grado di centrare propriamente i punti, probabilmente dovuti a qualche errore nella computazione della matrice di rotazione o di traslazione, pertanto continuerò a lavorare anche dopo la consegna al miglioramento del codice affinché l'assigment venga completato del tutto.\n",
    "\n",
    "La versione più recente di questo assigment è disponibile su [github](https://github.com/Montenigri/VisioneArtificiale/tree/main/Calibrazione)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Calibrate as cb\n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grazie al paper già citato scritto da Wilhelm Burger, è stato possibile creare l'insieme di definizioni contenute in Calibrate.\n",
    "Le funzioni sono commentate brevemente all'interno della raccolta, per cui verrà descritto il flusso di lavoro e come le funzioni si interfacciano tra loro:\n",
    "\n",
    "La funzione che permette di ottenere i risultati per il primo punto è la funzione calibra che accetta in input un numero intero tra 4,8 e 16, che sono anche le dimensioni dei dataset richiesti.\n",
    "\n",
    "La funzione *calibra* richiama una funzione che raccoglie i valori degli spigoli della scacchiera e poi li normalizza tramite la funzione normalize_points oltre che formattarli per gli usi futuri fatti dalla computazione dell'omografia.\n",
    "\n",
    "Una volta ritornati i valori vengono ciclati i risultati e calcolata l'omografia, questa lista di valori vengono poi passati alla funzione *get_intrinsc_parameters* che si occupa di calcolare di fatto i parametri intrinseci.\n",
    "\n",
    "il parametro della directory viene quindi passato anche alla funzione che sfrutta opencv2 per ottenere la matrice anche da li\n",
    "\n",
    "La funzione *getRT* permette, tramite la matrice H e K, di ottenere i valori della matrice di rotazione R e la matrice di traslazione T\n",
    "\n",
    "Infine la funzione *findHomographyForLab* permette di calcolare l'omografia dei punti del laboratorio utilizzando la matrice K ottenuta dal dataset di 16 foto e l'omografia calcolata sui punti 3d e 2d presi in laboratorio, infine sfrutta la funzione fornita dalla professoressa per stampare i punti sul pavimento (che effettivamente non fa)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chiamo quindi la funzione per calibrare la videocamera con 4 foto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K calcolata: \n",
      " [[1.07080044e+03 2.40767803e+00 5.11984155e+02]\n",
      " [0.00000000e+00 1.08121163e+03 3.73008033e+02]\n",
      " [0.00000000e+00 0.00000000e+00 1.00000000e+00]]\n",
      "CalibrateCamera: \n",
      " [[993.81323321   0.         566.67565488]\n",
      " [  0.         997.59541331 375.19013852]\n",
      " [  0.           0.           1.        ]]\n",
      "Errore: \n",
      " [[76.98720209  2.40767803 54.69150015]\n",
      " [ 0.         83.61621457  2.18210563]\n",
      " [ 0.          0.          0.        ]]\n"
     ]
    }
   ],
   "source": [
    "CameraIntrinsic4, CameraIntrinsicCalcolataDaCV24, Errore4 = cb.calibra(4)\n",
    "\n",
    "print(\"K calcolata: \\n\", CameraIntrinsic4)\n",
    "print(\"CalibrateCamera: \\n\", CameraIntrinsicCalcolataDaCV24)\n",
    "print(\"Errore: \\n\",Errore4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chiamo la funzione per calibrare la videocamera con 8 foto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K calcolata: \n",
      " [[ 1.08337872e+03 -1.88239037e+01  5.24358238e+02]\n",
      " [ 0.00000000e+00  1.10096738e+03  3.76282824e+02]\n",
      " [ 0.00000000e+00  0.00000000e+00  1.00000000e+00]]\n",
      "CalibrateCamera: \n",
      " [[994.64725456   0.         620.7827098 ]\n",
      " [  0.         995.86439794 379.62256068]\n",
      " [  0.           0.           1.        ]]\n",
      "Errore: \n",
      " [[ 88.73146819  18.82390374  96.42447216]\n",
      " [  0.         105.10298127   3.33973697]\n",
      " [  0.           0.           0.        ]]\n"
     ]
    }
   ],
   "source": [
    "CameraIntrinsic8, CameraIntrinsicCalcolataDaCV28, Errore8 = cb.calibra(8)\n",
    "\n",
    "print(\"K calcolata: \\n\", CameraIntrinsic8)\n",
    "print(\"CalibrateCamera: \\n\", CameraIntrinsicCalcolataDaCV28)\n",
    "print(\"Errore: \\n\",Errore8)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chiamo la funzione per calibrare la videocamera con 16 foto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K calcolata: \n",
      " [[ 1.10443278e+03 -2.10605782e+01  5.87698277e+02]\n",
      " [ 0.00000000e+00  1.11016145e+03  3.86632295e+02]\n",
      " [ 0.00000000e+00  0.00000000e+00  1.00000000e+00]]\n",
      "CalibrateCamera: \n",
      " [[1.00166431e+03 0.00000000e+00 6.55595647e+02]\n",
      " [0.00000000e+00 1.00143462e+03 3.85153768e+02]\n",
      " [0.00000000e+00 0.00000000e+00 1.00000000e+00]]\n",
      "Errore: \n",
      " [[102.76847812  21.06057824  67.89736995]\n",
      " [  0.         108.72682836   1.47852692]\n",
      " [  0.           0.           0.        ]]\n"
     ]
    }
   ],
   "source": [
    "CameraIntrinsic16, CameraIntrinsicCalcolataDaCV216, Errore16 = cb.calibra(16)\n",
    "\n",
    "print(\"K calcolata: \\n\", CameraIntrinsic16)\n",
    "print(\"CalibrateCamera: \\n\", CameraIntrinsicCalcolataDaCV216)\n",
    "print(\"Errore: \\n\",Errore16)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I punti rilevati in laboratorio si trovano alle coordinate espresse in cm per lo spazio 3d e pixel per lo spazio 2d:\n",
    "| Immagine | X3D  | Y3D  | X2D | Y2D |\n",
    "| -------- | ---- | ---- | --- | --- |\n",
    "| 125956   | -200 | 100  | 774 | 338 |\n",
    "| 13411    | -200 | 0    | 621 | 336 |\n",
    "| 13444    | -200 | -100 | 470 | 332 |\n",
    "| 13519    | -100 | -100 | 438 | 400 |\n",
    "| 13553    | -100 | 0    | 614 | 402 |\n",
    "| 13631    | -100 | 100  | 790 | 404 |\n",
    "| 1370     | 0    | -100 | 396 | 485 |\n",
    "| 13746    | 0    | 0    | 607 | 492 |\n",
    "| 13815    | 0    | 100  | 817 | 495 |\n",
    "| 13845    | 100  | -100 | 340 | 615 |\n",
    "| 13913    | 100  | 0    | 595 | 622 |\n",
    "| 13947    | 100  | 100  | 858 | 628 |\n",
    "| 131522   | 100  | -200 | 120 | 594 |\n",
    "| 131546   | 0    | -200 | 208 | 473 |\n",
    "| 13163    | -100 | -200 | 276 | 393 |\n",
    "| 131647   | -300 | 0    | 626 | 288 |\n",
    "\n",
    "\n",
    "Le corrispondenze sono già presenti all'interno della raccolta Calibrate, ma comunque riportate anche qui per completezza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_3d = np.array([ [-2,1], [-2,0], [-2,-1], [-1,-1], [-1,0], [-1,1] ,[0,-1], [0,0], [0,1], [1,-1], [0,1], [1,1], [1,-2], [0,-2], [-1,-2], [-3,0]])\n",
    "_2d = np.array([ [774,338], [621,336], [470,332], [438,400], [614,402], [790,404], [396,485], [607,492], [817,495], [340,615], [595,622], [858,628], [120,594], [208,473], [276,393], [626,288]])\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definisco un doppio ciclo for, il primo serve per ciclare in un range 0,4 estremo inferiore incluso, superiore escluso per dividere il set di immagini in 4 per fare cross validation, il set di validazione sarà dato dal vettore tagliato dalla posizione iesima alla i+1 esima\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = cb.get_camera_images(16)\n",
    "PATTERN_SIZE = (9, 6)\n",
    "multiply = 4\n",
    "criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 1000, 0.0001)\n",
    "errore = []\n",
    "\n",
    "for i in range (0,4):\n",
    "    objp = np.zeros((PATTERN_SIZE[1]*PATTERN_SIZE[0], 3), dtype=np.float64)\n",
    "    objp[:, :2] = np.indices(PATTERN_SIZE).T.reshape(-1, 2)\n",
    "\n",
    "    image_pointsVal = []\n",
    "    object_pointsVal = []\n",
    "    correspondencesVal = []\n",
    "    image_pointsTra = []\n",
    "    object_pointsTra = []\n",
    "    correspondencesTra = []\n",
    "    a = int(multiply * i)\n",
    "    b = int(multiply * i +1)\n",
    "    validation = images[a : b]\n",
    "    training = [i for i in images if i not in validation]\n",
    "    for (path, each) in training:\n",
    "        image = each\n",
    "        ret, angoli = cv2.findChessboardCorners(each, patternSize=PATTERN_SIZE)\n",
    "\n",
    "        if ret:\n",
    "            corners = corners.reshape(-1, 2)\n",
    "            if corners.shape[0] == objp.shape[0] :\n",
    "                corners2 = cv2.cornerSubPix(each, corners, (6,6),(1,1), criteria)\n",
    "                image_pointsTra.append(corners2)\n",
    "                object_pointsTra.append(objp[:,:-1]) #Togliamo Z perché ci interessano i punti nel piano XY\n",
    "                correspondencesTra.append([corners.astype(int), objp[:, :-1].astype(int)])\n",
    "\n",
    "    for (path, each) in validation:\n",
    "        image = each\n",
    "        ret, angoli = cv2.findChessboardCorners(each, patternSize=PATTERN_SIZE)\n",
    "\n",
    "        if ret:\n",
    "            corners = corners.reshape(-1, 2)\n",
    "            if corners.shape[0] == objp.shape[0] :\n",
    "                corners2 = cv2.cornerSubPix(each, corners, (6,6),(1,1), criteria)\n",
    "                image_pointsVal.append(corners2)\n",
    "                object_pointsVal.append(objp[:,:-1]) #Togliamo Z perché ci interessano i punti nel piano XY\n",
    "                correspondencesVal.append([corners.astype(int), objp[:, :-1].astype(int)])\n",
    "    errore[i]= [np.abs(image_pointsTra-image_pointsVal),np.abs(object_pointsTra-object_pointsVal),np.abs(correspondencesTra-correspondencesVal)]\n",
    "    \n",
    " "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Proietto quindi i punti sul piano del laboratorio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb.findHomographyForLab()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
