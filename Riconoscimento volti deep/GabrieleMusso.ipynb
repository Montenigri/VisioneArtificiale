{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spiegazione del progetto, richieste e caratteristiche\n",
    "Introduzione brevissima su cosa ho usato\n",
    "Struttura del progetto e delle cartelle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, Flatten, Dense, MaxPool2D, Dropout,RandomBrightness,RandomRotation,RandomFlip,RandomZoom\n",
    "from keras.utils import to_categorical\n",
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "from sklearn.utils import shuffle\n",
    "from math import floor\n",
    "from itertools import chain\n",
    "from tqdm import tqdm\n",
    "import pickle"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cosa è yolo, perché lo usiamo, come funziona\n",
    "\n",
    "spiegazione nomi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://github.com/derronqi/yolov8-face\n",
    "#https://docs.ultralytics.com/\n",
    "detect = YOLO('yolov8n-face.pt')\n",
    "\n",
    "nomi = [\"Davide\",\"Francesco\", \"Gabriele\", \"Stefano\", \"Unknown\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collegandosi alla struttura spiegata in precedenza, dire cosa fa questa funzione: perché uso chain, perché dopo cambio i nomi con gli indici"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDataset(root=\"train\"):\n",
    "\n",
    "    listDir = os.listdir(root)\n",
    "    foto = []\n",
    "    tag = []\n",
    "\n",
    "    for dir in listDir:\n",
    "        imgs =  glob.glob(f\"{root}/{dir}/*.jpg\")\n",
    "        dirs = [dir]*len(imgs)\n",
    "        foto = list(chain(foto,imgs))\n",
    "        tag = list(chain(tag,dirs))\n",
    "        \n",
    "\n",
    "\n",
    "    for k in tqdm(range(len(tag)), desc= \"Changing names to index\"):\n",
    "        for i in range(len(nomi)):\n",
    "            if tag[k] == nomi[i]:\n",
    "                tag[k] = i\n",
    "\n",
    "    tag = list(map(int, tag))\n",
    "    foto,tag = shuffle(foto,tag, random_state=42)\n",
    "    return foto,tag"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spiegare la divisione del set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSets(x,y, percentage=[0.6,0.2]):\n",
    "    length = len(x)\n",
    "    \n",
    "    trainLen = floor(percentage[0]*length)\n",
    "    valLen = floor(percentage[1]*length) + trainLen\n",
    "\n",
    "    for i in tqdm(range(len(x)), desc= \"Detecting faces\"):\n",
    "        x[i],_ = findFaces(cv2.imread(x[i]),maxDet=1)\n",
    "\n",
    "    x = list(map(np.asarray, x))\n",
    "    \n",
    "    x = np.array(x)\n",
    "    y = np.array(y)\n",
    "    train = (x[:trainLen],y[:trainLen])\n",
    "    val = (x[trainLen:valLen],y[trainLen:valLen]) \n",
    "    test  = (x[valLen:],y[valLen:])\n",
    "\n",
    "    return train, val, test"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cosa e come fa questa questa funzione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findFaces(frame, maxDet = 10):\n",
    "    img_test = detect.predict(source=frame,max_det=maxDet,verbose=False)\n",
    "    faces = []\n",
    "    boxesDetect = []\n",
    "    for result in img_test:\n",
    "        boxes = result.boxes  \n",
    "        boxes = boxes.numpy()\n",
    "        face = frame[int(boxes.xyxy[0][1]):int(boxes.xyxy[0][3]),int(boxes.xyxy[0][0]):int(boxes.xyxy[0][2]),:]\n",
    "        #Da mettere con padding per non storpiare le facce\n",
    "        face =  cv2.resize(face, (64,64))\n",
    "        faces = list(chain(faces,face))\n",
    "        boxesDetect = list(chain(boxesDetect,boxes))\n",
    "    \n",
    "    return faces, boxesDetect"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Caricamento dei pesi se esistono, altrimenti si calcolano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(\"train.pkl\") and os.path.exists(\"val.pkl\") and os.path.exists(\"test.pkl\"):\n",
    "    with open(\"train.pkl\",\"rb\") as ds:\n",
    "        train = pickle.load(ds)\n",
    "    with open(\"val.pkl\",\"rb\") as ds:\n",
    "        val = pickle.load(ds)\n",
    "    with open(\"test.pkl\",\"rb\") as ds:\n",
    "        test = pickle.load(ds)\n",
    "\n",
    "else: \n",
    "    x,y = getDataset()\n",
    "\n",
    "    train, val, test = getSets(x,y)\n",
    "\n",
    "    with open(\"train.pkl\",\"wb\") as ds:\n",
    "        pickle.dump(train,ds)\n",
    "\n",
    "    with open(\"val.pkl\",\"wb\") as ds:\n",
    "        pickle.dump(val,ds)\n",
    "\n",
    "    with open(\"test.pkl\",\"wb\") as ds:\n",
    "        pickle.dump(test,ds)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "divisione delle tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, Y_train) = train\n",
    "(X_val,Y_val) = val\n",
    "(X_test, Y_test) = test"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perché si fa, perché aggiungo invece di sostituire, perché uso quella mini rete neurale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = tf.keras.Sequential([\n",
    "  RandomFlip(\"horizontal\"),\n",
    "  RandomRotation(0.2),\n",
    "  RandomBrightness((-0.2,0.2)),\n",
    "  RandomZoom(.1, .1)\n",
    "])\n",
    "\n",
    "Xtrain = []\n",
    "Ytrain = []\n",
    "for i in tqdm(range(len(X_train)), desc= \"data augmentation\"):\n",
    "        Xtrain.append(data_augmentation(X_train[i]))\n",
    "        Xtrain.append(X_train[i])\n",
    "        Ytrain.append(Y_train[i])\n",
    "        Ytrain.append(Y_train[i])\n",
    "\n",
    "X_train = np.array(Xtrain)\n",
    "Y_train = np.array(Ytrain)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classificatore, spiegare cosa è, a cosa serve, come funziona, perché è costruito cosi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (5, 5), activation='relu', input_shape=(64, 64, 3)))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Conv2D(64, (5, 5), activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(5, activation='softmax'))\n",
    "\n",
    "model.compile(\n",
    "    optimizer=\"Adam\",\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    metrics=[keras.metrics.CategoricalAccuracy()]\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Caricamento del fit o creazione dei pesi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(\"modelClassificatore.h5\"):\n",
    "    model.load_weights('modelClassificatore.h5')\n",
    "\n",
    "else:\n",
    "    callback = keras.callbacks.EarlyStopping(monitor= \"val_loss\", patience=3)\n",
    "    model.fit(\n",
    "        X_train, to_categorical(Y_train), epochs=100, \n",
    "        batch_size=64, shuffle=True, \n",
    "        validation_data=(X_val,to_categorical(Y_val)),\n",
    "        callbacks=callback\n",
    "        )\n",
    "\n",
    "    model.save_weights('modelClassificatore.h5')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test per verificare quanto bene è andato l'addestramento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.evaluate(\n",
    "  X_test,\n",
    "  to_categorical(Y_test)\n",
    ")\n",
    "print(results)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funzione per classificare i frame, come lo faccio, cosa faccio e cosa ritorno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classificatore(frames):\n",
    "    #Per mantenere l'univocità dei volti sui frame, ciclo singolamente i frame per poi inserire le\n",
    "    #box ed i nomi\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "\n",
    "    for f in tqdm(range(len(frames)), desc=\"Face recognition per frame\"):\n",
    "        faces,boxes = findFaces(frames[f])\n",
    "      \n",
    "        faces = np.array(faces)\n",
    "        faces = np.expand_dims(faces, axis=0)\n",
    "        #https://www.tensorflow.org/api_docs/python/tf/keras/Model#predict\n",
    "      \n",
    "        predict = model.predict(faces, verbose=False)\n",
    "        for (boxe,pred) in zip(boxes, predict[0]):\n",
    "            frames[f] = cv2.putText(frames[f], nomi[int(pred)] , (int(boxe.xyxy[0][0])-5,int(boxe.xyxy[0][1])-5),font, 1,(255,255,255),2)\n",
    "            frames[f] = cv2.rectangle(frames[f], (int(boxe.xyxy[0][0]), int(boxe.xyxy[0][1])), (int(boxe.xyxy[0][2]), int(boxe.xyxy[0][3])), (255, 0, 255), 4)\n",
    "       \n",
    "    return frames"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Caricamento del video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video = cv2.VideoCapture(\"Video finale senza riconoscimento.mp4\")\n",
    "frames = []\n",
    "if (video.isOpened() == False):\n",
    "    print(\"Error opening video file\")\n",
    "while(video.isOpened()):\n",
    "  ret, frame = video.read()\n",
    "  if ret == True:\n",
    "        frames.append(frame)\n",
    "  else:\n",
    "      break\n",
    "\n",
    "results = classificatore(frames[:1500])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Salvataggio del video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "height, width, channels = results[0].shape\n",
    "size = (width,height)\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "\n",
    "out15 = cv2.VideoWriter('project_video_finale.mp4',fourcc, 15, size)\n",
    "\n",
    "for i in tqdm(range(len(results)), desc=\"Saving frames into video\"):\n",
    "    out15.write(results[i])\n",
    "out15.release()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
